{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 start monitoring & logging on Azure AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change ${PJ_ROOT} to your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PJ_ROOT=\"${HOME}/core\"\n",
    "cd ${PJ_ROOT};pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "/Users/user/core\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ${PJ_ROOT}/docs/environments/azure_aks/env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start fiware cygnus for elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f cygnus/cygnus-elasticsearch-service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f cygnus/cygnus-elasticsearch-deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get pods -l app=cygnus-elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                    READY   STATUS    RESTARTS   AGE\n",
    "cygnus-elasticsearch-689b7f5fd8-dtptx   1/1     Running   0          36s\n",
    "cygnus-elasticsearch-689b7f5fd8-wj5vm   1/1     Running   0          36s\n",
    "cygnus-elasticsearch-689b7f5fd8-xnhhj   1/1     Running   0          36s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get services -l app=cygnus-elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)             AGE\n",
    "cygnus-elasticsearch   ClusterIP   10.0.93.83   <none>        5050/TCP,8081/TCP   1m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start prometheus & grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install prometheus-operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   po\n",
      "LAST DEPLOYED: Sat Jul  6 12:52:49 2019\n",
      "NAMESPACE: monitoring\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Alertmanager\n",
      "NAME                                 AGE\n",
      "po-prometheus-operator-alertmanager  3s\n",
      "\n",
      "==> v1/ClusterRole\n",
      "NAME                                   AGE\n",
      "po-grafana-clusterrole                 5s\n",
      "po-prometheus-operator-alertmanager    4s\n",
      "po-prometheus-operator-operator        4s\n",
      "po-prometheus-operator-operator-psp    4s\n",
      "po-prometheus-operator-prometheus      4s\n",
      "po-prometheus-operator-prometheus-psp  4s\n",
      "psp-po-kube-state-metrics              4s\n",
      "\n",
      "==> v1/ClusterRoleBinding\n",
      "NAME                                   AGE\n",
      "po-grafana-clusterrolebinding          4s\n",
      "po-prometheus-operator-alertmanager    4s\n",
      "po-prometheus-operator-operator        4s\n",
      "po-prometheus-operator-operator-psp    4s\n",
      "po-prometheus-operator-prometheus      4s\n",
      "po-prometheus-operator-prometheus-psp  4s\n",
      "psp-po-kube-state-metrics              4s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                                                      DATA  AGE\n",
      "po-grafana                                                1     5s\n",
      "po-grafana-config-dashboards                              1     5s\n",
      "po-grafana-test                                           1     5s\n",
      "po-prometheus-operator-etcd                               1     5s\n",
      "po-prometheus-operator-grafana-datasource                 1     5s\n",
      "po-prometheus-operator-k8s-cluster-rsrc-use               1     5s\n",
      "po-prometheus-operator-k8s-coredns                        1     5s\n",
      "po-prometheus-operator-k8s-node-rsrc-use                  1     5s\n",
      "po-prometheus-operator-k8s-resources-cluster              1     5s\n",
      "po-prometheus-operator-k8s-resources-namespace            1     5s\n",
      "po-prometheus-operator-k8s-resources-pod                  1     5s\n",
      "po-prometheus-operator-k8s-resources-workload             1     5s\n",
      "po-prometheus-operator-k8s-resources-workloads-namespace  1     5s\n",
      "po-prometheus-operator-nodes                              1     5s\n",
      "po-prometheus-operator-persistentvolumesusage             1     5s\n",
      "po-prometheus-operator-pods                               1     5s\n",
      "po-prometheus-operator-statefulset                        1     5s\n",
      "\n",
      "==> v1/Deployment\n",
      "NAME                             READY  UP-TO-DATE  AVAILABLE  AGE\n",
      "po-kube-state-metrics            0/1    1           0          4s\n",
      "po-prometheus-operator-operator  0/1    1           0          4s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                                              READY  STATUS             RESTARTS  AGE\n",
      "po-grafana-d7fd78f54-69tx7                        0/2    Init:0/1           0         3s\n",
      "po-kube-state-metrics-64fdf7d84d-zmnxj            0/1    ContainerCreating  0         3s\n",
      "po-prometheus-node-exporter-77cdm                 0/1    ContainerCreating  0         4s\n",
      "po-prometheus-node-exporter-cq9wr                 0/1    Running            0         3s\n",
      "po-prometheus-node-exporter-q94h5                 0/1    ContainerCreating  0         3s\n",
      "po-prometheus-operator-operator-7776c6dd9f-vswv9  0/1    ContainerCreating  0         3s\n",
      "\n",
      "==> v1/Prometheus\n",
      "NAME                               AGE\n",
      "po-prometheus-operator-prometheus  3s\n",
      "\n",
      "==> v1/PrometheusRule\n",
      "NAME                                                         AGE\n",
      "po-prometheus-operator-alertmanager.rules                    3s\n",
      "po-prometheus-operator-etcd                                  3s\n",
      "po-prometheus-operator-general.rules                         3s\n",
      "po-prometheus-operator-k8s.rules                             3s\n",
      "po-prometheus-operator-kube-apiserver.rules                  3s\n",
      "po-prometheus-operator-kube-prometheus-node-alerting.rules   3s\n",
      "po-prometheus-operator-kube-prometheus-node-recording.rules  3s\n",
      "po-prometheus-operator-kube-scheduler.rules                  3s\n",
      "po-prometheus-operator-kubernetes-absent                     3s\n",
      "po-prometheus-operator-kubernetes-apps                       3s\n",
      "po-prometheus-operator-kubernetes-resources                  3s\n",
      "po-prometheus-operator-kubernetes-storage                    3s\n",
      "po-prometheus-operator-kubernetes-system                     3s\n",
      "po-prometheus-operator-node-network                          3s\n",
      "po-prometheus-operator-node-time                             3s\n",
      "po-prometheus-operator-node.rules                            3s\n",
      "po-prometheus-operator-prometheus-operator                   2s\n",
      "po-prometheus-operator-prometheus.rules                      2s\n",
      "\n",
      "==> v1/Role\n",
      "NAME             AGE\n",
      "po-grafana-test  4s\n",
      "\n",
      "==> v1/RoleBinding\n",
      "NAME             AGE\n",
      "po-grafana-test  4s\n",
      "\n",
      "==> v1/Secret\n",
      "NAME                                              TYPE    DATA  AGE\n",
      "alertmanager-po-prometheus-operator-alertmanager  Opaque  1     6s\n",
      "po-grafana                                        Opaque  3     6s\n",
      "\n",
      "==> v1/Service\n",
      "NAME                                            TYPE       CLUSTER-IP    EXTERNAL-IP  PORT(S)    AGE\n",
      "po-grafana                                      ClusterIP  10.0.17.182   <none>       80/TCP     4s\n",
      "po-kube-state-metrics                           ClusterIP  10.0.199.68   <none>       8080/TCP   4s\n",
      "po-prometheus-node-exporter                     ClusterIP  10.0.39.247   <none>       9100/TCP   4s\n",
      "po-prometheus-operator-alertmanager             ClusterIP  10.0.59.136   <none>       9093/TCP   4s\n",
      "po-prometheus-operator-coredns                  ClusterIP  None          <none>       9153/TCP   4s\n",
      "po-prometheus-operator-kube-controller-manager  ClusterIP  None          <none>       10252/TCP  4s\n",
      "po-prometheus-operator-kube-etcd                ClusterIP  None          <none>       2379/TCP   4s\n",
      "po-prometheus-operator-kube-scheduler           ClusterIP  None          <none>       10251/TCP  4s\n",
      "po-prometheus-operator-operator                 ClusterIP  10.0.187.114  <none>       8080/TCP   4s\n",
      "po-prometheus-operator-prometheus               ClusterIP  10.0.151.62   <none>       9090/TCP   4s\n",
      "\n",
      "==> v1/ServiceAccount\n",
      "NAME                                 SECRETS  AGE\n",
      "po-grafana                           1        5s\n",
      "po-grafana-test                      1        5s\n",
      "po-kube-state-metrics                1        5s\n",
      "po-prometheus-node-exporter          1        5s\n",
      "po-prometheus-operator-alertmanager  1        5s\n",
      "po-prometheus-operator-operator      1        5s\n",
      "po-prometheus-operator-prometheus    1        5s\n",
      "\n",
      "==> v1/ServiceMonitor\n",
      "NAME                                            AGE\n",
      "po-prometheus-operator-alertmanager             2s\n",
      "po-prometheus-operator-apiserver                2s\n",
      "po-prometheus-operator-coredns                  2s\n",
      "po-prometheus-operator-grafana                  2s\n",
      "po-prometheus-operator-kube-controller-manager  2s\n",
      "po-prometheus-operator-kube-etcd                2s\n",
      "po-prometheus-operator-kube-scheduler           2s\n",
      "po-prometheus-operator-kube-state-metrics       2s\n",
      "po-prometheus-operator-kubelet                  2s\n",
      "po-prometheus-operator-node-exporter            2s\n",
      "po-prometheus-operator-operator                 2s\n",
      "po-prometheus-operator-prometheus               2s\n",
      "\n",
      "==> v1beta1/ClusterRole\n",
      "NAME                             AGE\n",
      "po-kube-state-metrics            5s\n",
      "psp-po-prometheus-node-exporter  4s\n",
      "\n",
      "==> v1beta1/ClusterRoleBinding\n",
      "NAME                             AGE\n",
      "po-kube-state-metrics            4s\n",
      "psp-po-prometheus-node-exporter  4s\n",
      "\n",
      "==> v1beta1/DaemonSet\n",
      "NAME                         DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE  NODE SELECTOR  AGE\n",
      "po-prometheus-node-exporter  3        3        0      3           0          <none>         4s\n",
      "\n",
      "==> v1beta1/PodSecurityPolicy\n",
      "NAME                                 PRIV   CAPS      SELINUX           RUNASUSER  FSGROUP    SUPGROUP  READONLYROOTFS  VOLUMES\n",
      "po-grafana                           false  RunAsAny  RunAsAny          RunAsAny   RunAsAny   false     configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim\n",
      "po-grafana-test                      false  RunAsAny  RunAsAny          RunAsAny   RunAsAny   false     configMap,downwardAPI,emptyDir,projected,secret\n",
      "po-kube-state-metrics                false  RunAsAny  MustRunAsNonRoot  MustRunAs  MustRunAs  false     secret\n",
      "po-prometheus-node-exporter          false  RunAsAny  RunAsAny          MustRunAs  MustRunAs  false     configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim,hostPath\n",
      "po-prometheus-operator-alertmanager  false  RunAsAny  RunAsAny          MustRunAs  MustRunAs  false     configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "po-prometheus-operator-operator      false  RunAsAny  RunAsAny          MustRunAs  MustRunAs  false     configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim\n",
      "po-prometheus-operator-prometheus    false  RunAsAny  RunAsAny          MustRunAs  MustRunAs  false     configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim\n",
      "\n",
      "==> v1beta1/Role\n",
      "NAME        AGE\n",
      "po-grafana  4s\n",
      "\n",
      "==> v1beta1/RoleBinding\n",
      "NAME        AGE\n",
      "po-grafana  4s\n",
      "\n",
      "==> v1beta2/Deployment\n",
      "NAME        READY  UP-TO-DATE  AVAILABLE  AGE\n",
      "po-grafana  0/1    1           0          4s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "The Prometheus Operator has been installed. Check its status by running:\n",
      "  kubectl --namespace monitoring get pods -l \"release=po\"\n",
      "\n",
      "Visit https://github.com/coreos/prometheus-operator for instructions on how\n",
      "to create & configure Alertmanager and Prometheus instances using the Operator.\n"
     ]
    }
   ],
   "source": [
    "helm install stable/prometheus-operator --name po --namespace monitoring -f monitoring/prometheus-operator-azure.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                               READY   STATUS    RESTARTS   AGE\n",
      "po-prometheus-operator-operator-7776c6dd9f-vswv9   1/1     Running   0          6m9s\n"
     ]
    }
   ],
   "source": [
    "kubectl --namespace monitoring get pods -l \"app=prometheus-operator-operator,release=po\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                               READY   STATUS    RESTARTS   AGE\n",
    "po-prometheus-operator-operator-7cf7c5cc97-78h9g   1/1     Running   0          2m28s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\n",
      "po-prometheus-node-exporter   3         3         3       3            3           <none>          20m\n"
     ]
    }
   ],
   "source": [
    "kubectl get daemonsets --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\n",
    "po-prometheus-node-exporter   4         4         4       4            4           <none>          2m48s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get deployments --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                              READY   UP-TO-DATE   AVAILABLE   AGE\n",
    "po-grafana                        1/1     1            1           3m51s\n",
    "po-kube-state-metrics             1/1     1            1           3m51s\n",
    "po-prometheus-operator-operator   1/1     1            1           3m51s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                               READY   AGE\n",
      "alertmanager-po-prometheus-operator-alertmanager   1/1     21m\n",
      "prometheus-po-prometheus-operator-prometheus       1/1     21m\n"
     ]
    }
   ],
   "source": [
    "kubectl get statefulsets --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                               READY   AGE\n",
    "alertmanager-po-prometheus-operator-alertmanager   1/1     3m44s\n",
    "prometheus-po-prometheus-operator-prometheus       1/1     3m34s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                 READY   STATUS    RESTARTS   AGE\n",
      "alertmanager-po-prometheus-operator-alertmanager-0   2/2     Running   0          22m\n",
      "po-grafana-d7fd78f54-69tx7                           2/2     Running   0          22m\n",
      "po-kube-state-metrics-64fdf7d84d-zmnxj               1/1     Running   0          22m\n",
      "po-prometheus-node-exporter-77cdm                    1/1     Running   0          22m\n",
      "po-prometheus-node-exporter-cq9wr                    1/1     Running   0          22m\n",
      "po-prometheus-node-exporter-q94h5                    1/1     Running   0          22m\n",
      "po-prometheus-operator-operator-7776c6dd9f-vswv9     1/1     Running   0          22m\n",
      "prometheus-po-prometheus-operator-prometheus-0       3/3     Running   1          21m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                                 READY   STATUS    RESTARTS   AGE\n",
    "alertmanager-po-prometheus-operator-alertmanager-0   2/2     Running   0          3m56s\n",
    "po-grafana-fbc85bc4b-5k2s8                           2/2     Running   0          4m32s\n",
    "po-kube-state-metrics-64fdf7d84d-v9d8h               1/1     Running   0          4m32s\n",
    "po-prometheus-node-exporter-4fptr                    1/1     Running   0          4m32s\n",
    "po-prometheus-node-exporter-92lzp                    1/1     Running   0          4m32s\n",
    "po-prometheus-node-exporter-h8hff                    1/1     Running   0          4m32s\n",
    "po-prometheus-node-exporter-76pc4                    1/1     Running   0          4m32s\n",
    "po-prometheus-operator-operator-7cf7c5cc97-78h9g     1/1     Running   0          4m32s\n",
    "prometheus-po-prometheus-operator-prometheus-0       3/3     Running   1          3m46s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE\n",
      "alertmanager-operated                 ClusterIP   None           <none>        9093/TCP,6783/TCP   22m\n",
      "po-grafana                            ClusterIP   10.0.17.182    <none>        80/TCP              22m\n",
      "po-kube-state-metrics                 ClusterIP   10.0.199.68    <none>        8080/TCP            22m\n",
      "po-prometheus-node-exporter           ClusterIP   10.0.39.247    <none>        9100/TCP            22m\n",
      "po-prometheus-operator-alertmanager   ClusterIP   10.0.59.136    <none>        9093/TCP            22m\n",
      "po-prometheus-operator-operator       ClusterIP   10.0.187.114   <none>        8080/TCP            22m\n",
      "po-prometheus-operator-prometheus     ClusterIP   10.0.151.62    <none>        9090/TCP            22m\n",
      "prometheus-operated                   ClusterIP   None           <none>        9090/TCP            22m\n"
     ]
    }
   ],
   "source": [
    "kubectl get services --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE\n",
    "alertmanager-operated                 ClusterIP   None           <none>        9093/TCP,6783/TCP   6m4s\n",
    "po-grafana                            ClusterIP   10.0.67.251    <none>        80/TCP              6m40s\n",
    "po-kube-state-metrics                 ClusterIP   10.0.104.75    <none>        8080/TCP            6m40s\n",
    "po-prometheus-node-exporter           ClusterIP   10.0.103.93    <none>        9100/TCP            6m40s\n",
    "po-prometheus-operator-alertmanager   ClusterIP   10.0.57.200    <none>        9093/TCP            6m40s\n",
    "po-prometheus-operator-operator       ClusterIP   10.0.37.49     <none>        8080/TCP            6m40s\n",
    "po-prometheus-operator-prometheus     ClusterIP   10.0.229.252   <none>        9090/TCP            6m40s\n",
    "prometheus-operated                   ClusterIP   None           <none>        9090/TCP            5m54s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                                                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\n",
      "prometheus-alertmanager-storage-claim-alertmanager-po-prometheus-operator-alertmanager-0   Bound    pvc-8fd42973-9fa1-11e9-8e06-7200ae7cb77a   30Gi       RWO            managed-premium   23m\n",
      "prometheus-prometheus-storage-claim-prometheus-po-prometheus-operator-prometheus-0         Bound    pvc-95d7eb81-9fa1-11e9-8e06-7200ae7cb77a   30Gi       RWO            managed-premium   23m\n"
     ]
    }
   ],
   "source": [
    "kubectl get persistentvolumeclaims --namespace monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                                                                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\n",
    "prometheus-alertmanager-storage-claim-alertmanager-po-prometheus-operator-alertmanager-0   Bound    pvc-82a98fe2-9f94-11e9-8e06-7200ae7cb77a   30Gi       RWO            managed-premium   119s\n",
    "prometheus-prometheus-storage-claim-prometheus-po-prometheus-operator-prometheus-0         Bound    pvc-88b5edbb-9f94-11e9-8e06-7200ae7cb77a   30Gi       RWO            managed-premium   109s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edit some prometheus rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubectl edit --namespace=monitoring prometheusrules po-prometheus-operator-general.rules\n"
     ]
    }
   ],
   "source": [
    "echo 'kubectl edit --namespace=monitoring prometheusrules po-prometheus-operator-general.rules'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "       for: 10m\n",
    "       labels:\n",
    "         severity: warning\n",
    "-    - alert: Watchdog\n",
    "-      annotations:\n",
    "-        message: |\n",
    "-          This is an alert meant to ensure that the entire alerting pipeline is functional.\n",
    "-          This alert is always firing, therefore it should always be firing in Alertmanager\n",
    "-          and always fire against a receiver. There are integrations with various notification\n",
    "-          mechanisms that send a notification when this alert is not firing. For example the\n",
    "-          \"DeadMansSnitch\" integration in PagerDuty.\n",
    "-      expr: vector(1)\n",
    "-      labels:\n",
    "-        severity: none\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubectl edit --namespace=monitoring prometheusrules po-prometheus-operator-kubernetes-absent\n"
     ]
    }
   ],
   "source": [
    "echo 'kubectl edit --namespace=monitoring prometheusrules po-prometheus-operator-kubernetes-absent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "       for: 15m\n",
    "       labels:\n",
    "         severity: critical\n",
    "-    - alert: KubeControllerManagerDown\n",
    "-      annotations:\n",
    "-        message: KubeControllerManager has disappeared from Prometheus target discovery.\n",
    "-        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown\n",
    "-      expr: absent(up{job=\"kube-controller-manager\"} == 1)\n",
    "-      for: 15m\n",
    "-      labels:\n",
    "-        severity: critical\n",
    "-    - alert: KubeSchedulerDown\n",
    "-      annotations:\n",
    "-        message: KubeScheduler has disappeared from Prometheus target discovery.\n",
    "-        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown\n",
    "-      expr: absent(up{job=\"kube-scheduler\"} == 1)\n",
    "-      for: 15m\n",
    "-      labels:\n",
    "-        severity: critical\n",
    "     - alert: KubeStateMetricsDown\n",
    "       annotations:\n",
    "         message: KubeStateMetrics has disappeared from Prometheus target discovery.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubectl --namespace monitoring port-forward $(kubectl get pod --namespace monitoring -l prometheus=kube-prometheus -l app=prometheus -o template --template \"{{(index .items 0).metadata.name}}\") 9090:9090\n"
     ]
    }
   ],
   "source": [
    "echo 'kubectl --namespace monitoring port-forward $(kubectl get pod --namespace monitoring -l prometheus=kube-prometheus -l app=prometheus -o template --template \"{{(index .items 0).metadata.name}}\") 9090:9090'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "open http://localhost:9090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdg-open http://localhost:9090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. confirm Prometheus\n",
    "    * no `Target` is down.\n",
    "    * no `Alert` is fired except CPU or Memory resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### patch grafana service\n",
    "* add the \"annotation\" of ambassador in order to access from Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/po-grafana patched\n"
     ]
    }
   ],
   "source": [
    "kubectl patch service --namespace monitoring po-grafana -p '{\"metadata\": {\"annotations\": {\"getambassador.io/config\": \"---\\napiVersion: ambassador/v0\\nkind:  Mapping\\nname:  grafana-mapping\\nprefix: /\\nhost: \\\"^grafana\\\\\\\\..+$\\\"\\nhost_regex: true\\nservice: http://po-grafana.monitoring:80\\n\"}}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register DNS A Record for grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTPS_IPADDR=$(kubectl get services -l app=ambassador -o json | jq '.items[0].status.loadBalancer.ingress[0].ip' -r)\n",
    "az network dns record-set a add-record --resource-group ${DNS_ZONE_RG} --zone-name \"${DOMAIN}\" --record-set-name \"grafana\" --ipv4-address \"${HTTPS_IPADDR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open https://grafana.${DOMAIN}/login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdg-open https://grafana.${DOMAIN}/login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. login grafana\n",
    "    * At the first, a admin user (`admin`/`prom-operator`) is available.\n",
    "2. change the admin's password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start Elasticsearch, fluentd and Kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/elasticsearch-azure-service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/elasticsearch-azure-deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get statefulsets --namespace monitoring -l k8s-app=elasticsearch-logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                    READY   AGE\n",
    "elasticsearch-logging   2/2     5m18s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get pods --namespace monitoring -l k8s-app=elasticsearch-logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                      READY     STATUS    RESTARTS   AGE\n",
    "elasticsearch-logging-0   1/1       Running   0          4m\n",
    "elasticsearch-logging-1   1/1       Running   0          2m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get services --namespace monitoring -l k8s-app=elasticsearch-logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                    TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
    "elasticsearch-logging   ClusterIP   10.0.80.88   <none>        9200/TCP   4m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get persistentvolumeclaims -n monitoring -l k8s-app=elasticsearch-logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                                            STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\n",
    "elasticsearch-logging-elasticsearch-logging-0   Bound     pvc-238139db-b014-11e8-b618-066567bdfa8c   64Gi       RWO            managed-premium   4m\n",
    "elasticsearch-logging-elasticsearch-logging-1   Bound     pvc-70ca5ec3-b014-11e8-b618-066567bdfa8c   64Gi       RWO            managed-premium   2m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl exec -it elasticsearch-logging-0 --namespace monitoring -- curl -H \"Content-Type: application/json\" -X PUT http://elasticsearch-logging:9200/_cluster/settings -d '{\"transient\": {\"cluster.routing.allocation.enable\":\"all\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start fluentd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/fluentd-es-configmap.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/fluentd-es-ds.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get daemonsets --namespace monitoring -l k8s-app=fluentd-es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\n",
    "fluentd-es-v2.2.0   4         4         4       4            4           <none>          53s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get pods --namespace monitoring -l k8s-app=fluentd-es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                      READY   STATUS    RESTARTS   AGE\n",
    "fluentd-es-v2.2.0-8sv45   1/1     Running   0          1m\n",
    "fluentd-es-v2.2.0-96ghs   1/1     Running   0          1m\n",
    "fluentd-es-v2.2.0-cjhtc   1/1     Running   0          1m\n",
    "fluentd-es-v2.2.0-djzff   1/1     Running   0          1m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start Kibana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/kibana-service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/kibana-deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get pods --namespace monitoring -l k8s-app=kibana-logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                              READY     STATUS    RESTARTS   AGE\n",
    "kibana-logging-7444956bf8-stnfm   1/1       Running   0          1m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register DNS A Record for Kibana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTPS_IPADDR=$(kubectl get services -l app=ambassador -o json | jq '.items[0].status.loadBalancer.ingress[0].ip' -r)\n",
    "az network dns record-set a add-record --resource-group ${DNS_ZONE_RG} --zone-name \"${DOMAIN}\" --record-set-name \"kibana\" --ipv4-address \"${HTTPS_IPADDR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start curator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/curator-configmap.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f logging/curator-cronjob.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get cronjobs --namespace monitoring -l k8s-app=elasticsearch-curator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example)\n",
    "```\n",
    "NAME                    SCHEDULE     SUSPEND   ACTIVE    LAST SCHEDULE   AGE\n",
    "elasticsearch-curator   0 18 * * *   False     0         <none>          7s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm basic auth username & password for Kibana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ${PJ_ROOT}/secrets/auth-tokens.json | jq '.[]|select(.host == \"kibana\\\\..+$\")|.settings.basic_auths[0].username' -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ${PJ_ROOT}/secrets/auth-tokens.json | jq '.[]|select(.host == \"kibana\\\\..+$\")|.settings.basic_auths[0].password' -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup Kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open https://kibana.${DOMAIN}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdg-open https://kibana.${DOMAIN}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Login kibana by basic authorization using above username and password\n",
    "1. show `Management -> Index Patterns`\n",
    "2. set `logstash-*` as Index Pattern, and push `Next step`\n",
    "3. set `@timestamp` as Time Filter field name, and push `Create index pattern`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open https://grafana.${DOMAIN}/login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdg-open https://grafana.${DOMAIN}/login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add `elasticsearch` dashboard to grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add a new Data Source (ElasticSearch)\n",
    "    * Name: `elasticsearch`\n",
    "    * URL: `http://elasticsearch-logging:9200`\n",
    "    * Access: `Server(Default)`\n",
    "    * Index name: `logstash-*`\n",
    "    * Time field name: `@timestamp`\n",
    "    * Version: `6.0+`\n",
    "2. import `monitoring/dashboard_elasticsearch.json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
